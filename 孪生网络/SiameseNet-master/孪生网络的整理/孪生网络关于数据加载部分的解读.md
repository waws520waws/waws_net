孪生网络关于数据加载部分的解读

load_data.py

#### 1.导包

```python
import sys
import numpy as np
import cv2 as cv
import pickle
import os
import matplotlib.pyplot as plt
```

#### 2.文件路径的构建

```python
data_path = './dataset/'

# 训练数据地址
train_folder = os.path.join(data_path, 'images_background')
# 验证数据地址
valpath = os.path.join(data_path, 'images_evaluation')

save_path = './dataset/'
```

#### 3.加载图片(==核心==)

* ![image-20210416113857530](C:\Users\a21036\AppData\Roaming\Typora\typora-user-images\image-20210416113857530.png)
* 没有解压数据需要先解压数据
* 我们可以先观察一下目录的结构，层级关系如下
  * dataset
    * 训练数据
      * 字符名称
        * 字符标号
          * 图片
          * 图片
        * 字符标号
* 所以从dataset向下三层循环得到我们想要的图片数据进行加载
* 最终生成**X**和对应的**y**的数据，还有一个名称字典(方便后面去加载数据的名称)

```python
def loadimgs(path, n=0):
    # 数据没有解压，就先解压
    if not os.path.exists(path):
        print("You must unzip {}.zip.".format(path))
        exit(-1)

    X = []
    y = []
    cat_dict = {}
    lang_dict = {}
    curr_y = n
    # 加载每个字母，方便后面分离他们
    for alphabet in os.listdir(path):
        print("loading alphabet: " + alphabet)

        # 建立对应的映射关系，各个语言所包含的字母从 多少到多少
        lang_dict[alphabet] = [curr_y, None]
        alphabet_path = os.path.join(path, alphabet)

        # 每个不同语言又有不同的字母，分开加载
        for letter in os.listdir(alphabet_path):
            # 记录 语言、字母
            cat_dict[curr_y] = (alphabet, letter)
            category_images = []
            letter_path = os.path.join(alphabet_path, letter)

            # 记录每个字母的不同手写状态
            for filename in os.listdir(letter_path):
                image_path = os.path.join(letter_path, filename)
                image = cv.imread(image_path, cv.IMREAD_GRAYSCALE)
                category_images.append(image)
                y.append(curr_y)

            # 把一个类别统一的加载到X列表中
            X.append(np.stack(category_images))

            curr_y += 1
            lang_dict[alphabet][1] = curr_y - 1

    # 变成(19280, 1)的数据
    y = np.vstack(y)
    # 变成(964, 20, 105, 105, 3)的数据
    X = np.stack(X)

    return X, y, lang_dict
```

#### 4.将已经处理好的数据我们存储在pickle中，防止我们每次训练的时候，需要大量的时间处理数据

* 在训练数据从pickle文件中读取即可

```python
# 训练集的存储
X, _, c = loadimgs(train_folder)
with open(os.path.join(save_path, "train.pickle"), "wb") as f:
    # dumps 将数据通过特殊的形式转换为只有python语言认识的字符串
    pickle.dump((X, c), f)

# 验证集的存储
X, _, c = loadimgs(valpath)
with open(os.path.join(save_path, "valid.pickle"), "wb") as f:
    pickle.dump((X, c), f)
```

